name: LLM Evaluation CI/CD Pipeline with Slack Notifications

on:
  pull_request:
    types: [opened, synchronize, reopened]
    branches:
      - main
      - develop
  push:
    branches:
      - main
  workflow_dispatch:  # Allow manual triggering

env:
  PYTHON_VERSION: '3.11'
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

jobs:
  # ============================================================================
  # Job 1: Static Evaluation
  # ============================================================================
  static-evaluation:
    name: Static Evaluation Suite
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Create output directory
        run: |
          mkdir -p evaluation_outputs/static
      
      - name: Notify Slack - Evaluation Started
        if: env.SLACK_WEBHOOK_URL != ''
        run: |
          curl -X POST "${{ secrets.SLACK_WEBHOOK_URL }}" \
          -H 'Content-Type: application/json' \
          -d '{
            "text": "üî¨ *LLM Evaluation Started*",
            "blocks": [
              {
                "type": "header",
                "text": {
                  "type": "plain_text",
                  "text": "üî¨ LLM Evaluation Pipeline Started"
                }
              },
              {
                "type": "section",
                "fields": [
                  {
                    "type": "mrkdwn",
                    "text": "*Repository:*\n${{ github.repository }}"
                  },
                  {
                    "type": "mrkdwn",
                    "text": "*Branch:*\n${{ github.ref_name }}"
                  },
                  {
                    "type": "mrkdwn",
                    "text": "*Event:*\n${{ github.event_name }}"
                  },
                  {
                    "type": "mrkdwn",
                    "text": "*Triggered by:*\n${{ github.actor }}"
                  }
                ]
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "<${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Workflow Run>"
                }
              }
            ]
          }'
      
      - name: Run Static Evaluation
        id: static_eval
        run: |
          python run_static_evaluation.py \
            --output evaluation_outputs/static/results.json \
            --model gpt-4o-mini \
            --verbose
        continue-on-error: true
      
      - name: Upload evaluation results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: evaluation-results
          path: evaluation_outputs/static/results.json
      
      - name: Check Quality Gates
        id: quality_gates
        run: |
          python check_quality_gates.py \
            --results evaluation_outputs/static/results.json \
            --min-pass-rate 95 \
            --min-similarity 0.85 \
            --max-hallucination 0.02 \
            --critical-categories fraud_detection security \
            --verbose \
            --output-report evaluation_outputs/static/quality_report.txt
        continue-on-error: true
      
      - name: Upload quality report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: quality-report
          path: evaluation_outputs/static/quality_report.txt
      
      - name: Notify Slack - Evaluation Results
        if: always() && env.SLACK_WEBHOOK_URL != ''
        run: |
          # Read results
          if [ -f evaluation_outputs/static/results.json ]; then
            PASS_RATE=$(python -c "import json; print(json.load(open('evaluation_outputs/static/results.json'))['pass_rate'])")
            PASSED=$(python -c "import json; print(json.load(open('evaluation_outputs/static/results.json'))['passed'])")
            TOTAL=$(python -c "import json; print(json.load(open('evaluation_outputs/static/results.json'))['total_tests'])")
            
            # Determine status
            if (( $(echo "$PASS_RATE >= 95" | bc -l) )); then
              STATUS_EMOJI="‚úÖ"
              STATUS_TEXT="PASSED"
              COLOR="#2ecc71"
            elif (( $(echo "$PASS_RATE >= 90" | bc -l) )); then
              STATUS_EMOJI="‚ö†Ô∏è"
              STATUS_TEXT="WARNING"
              COLOR="#f39c12"
            else
              STATUS_EMOJI="‚ùå"
              STATUS_TEXT="FAILED"
              COLOR="#e74c3c"
            fi
            
            # Send notification
            curl -X POST "${{ secrets.SLACK_WEBHOOK_URL }}" \
            -H 'Content-Type: application/json' \
            -d "{
              \"text\": \"$STATUS_EMOJI Evaluation $STATUS_TEXT: ${PASS_RATE}%\",
              \"blocks\": [
                {
                  \"type\": \"header\",
                  \"text\": {
                    \"type\": \"plain_text\",
                    \"text\": \"$STATUS_EMOJI LLM Evaluation Results\"
                  }
                },
                {
                  \"type\": \"section\",
                  \"fields\": [
                    {
                      \"type\": \"mrkdwn\",
                      \"text\": \"*Status:*\n$STATUS_TEXT\"
                    },
                    {
                      \"type\": \"mrkdwn\",
                      \"text\": \"*Pass Rate:*\n${PASS_RATE}%\"
                    },
                    {
                      \"type\": \"mrkdwn\",
                      \"text\": \"*Tests Passed:*\n${PASSED}/${TOTAL}\"
                    },
                    {
                      \"type\": \"mrkdwn\",
                      \"text\": \"*Branch:*\n${{ github.ref_name }}\"
                    }
                  ]
                },
                {
                  \"type\": \"section\",
                  \"text\": {
                    \"type\": \"mrkdwn\",
                    \"text\": \"<${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Details>\"
                  }
                }
              ],
              \"attachments\": [
                {
                  \"color\": \"$COLOR\"
                }
              ]
            }"
          else
            # Send error notification
            curl -X POST "${{ secrets.SLACK_WEBHOOK_URL }}" \
            -H 'Content-Type: application/json' \
            -d '{
              "text": "‚ùå Evaluation failed to complete",
              "blocks": [
                {
                  "type": "header",
                  "text": {
                    "type": "plain_text",
                    "text": "‚ùå LLM Evaluation Error"
                  }
                },
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "Evaluation failed to produce results file.\n\n<${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Error Logs>"
                  }
                }
              ]
            }'
          fi
      
      - name: Post results to PR
        if: github.event_name == 'pull_request'
        env:
          PR_NUMBER: ${{ github.event.pull_request.number }}
          RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
        run: |
          python post_pr_results.py \
            --results evaluation_outputs/static/results.json \
            --pr-number $PR_NUMBER \
            --repo ${{ github.repository }} \
            --token ${{ secrets.GITHUB_TOKEN }} \
            --run-url $RUN_URL
      
      - name: Update commit status
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            let state = 'success';
            let description = 'Evaluation passed';
            
            try {
              const results = JSON.parse(
                fs.readFileSync('evaluation_outputs/static/results.json', 'utf8')
              );
              
              if (results.pass_rate < 95) {
                state = 'failure';
                description = `Evaluation failed: ${results.pass_rate.toFixed(1)}% pass rate`;
              } else {
                description = `Evaluation passed: ${results.pass_rate.toFixed(1)}% pass rate`;
              }
            } catch (error) {
              state = 'error';
              description = 'Evaluation error: Could not read results';
            }
            
            await github.rest.repos.createCommitStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              sha: context.sha,
              state: state,
              description: description,
              context: 'MLOps Evaluation'
            });
      
      - name: Fail if quality gates not met
        run: |
          if [ -f evaluation_outputs/static/results.json ]; then
            PASS_RATE=$(python -c "import json; print(json.load(open('evaluation_outputs/static/results.json'))['pass_rate'])")
            echo "Pass rate: $PASS_RATE%"
            
            if (( $(echo "$PASS_RATE < 95" | bc -l) )); then
              echo "‚ùå Quality gates failed: Pass rate $PASS_RATE% < 95%"
              exit 1
            else
              echo "‚úÖ Quality gates passed: Pass rate $PASS_RATE% >= 95%"
              exit 0
            fi
          else
            echo "‚ùå Results file not found"
            exit 1
          fi

  # ============================================================================
  # Job 2: Security & Compliance
  # ============================================================================
  security-check:
    name: Security & Compliance Check
    runs-on: ubuntu-latest
    needs: static-evaluation
    if: github.event_name == 'pull_request'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Check for secrets
        run: |
          echo "üîç Checking for accidentally committed secrets..."
          
          if grep -r "OPENAI_API_KEY.*sk-" . --exclude-dir={.git,node_modules,venv}; then
            echo "‚ùå Found hardcoded OpenAI API key!"
            exit 1
          fi
          
          if grep -r "ghp_" . --exclude-dir={.git,node_modules,venv}; then
            echo "‚ùå Found hardcoded GitHub token!"
            exit 1
          fi
          
          echo "‚úÖ No secrets found in code"
      
      - name: Check .env is gitignored
        run: |
          if git ls-files | grep -q "^\.env$"; then
            echo "‚ùå .env file is tracked by git!"
            exit 1
          fi
          echo "‚úÖ .env is properly gitignored"

  # ============================================================================
  # Job 3: Deployment (Only on main branch)
  # ============================================================================
  deploy:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [static-evaluation, security-check]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Download evaluation results
        uses: actions/download-artifact@v4
        with:
          name: evaluation-results
          path: evaluation_outputs/static/
      
      - name: Verify quality gates before deployment
        run: |
          PASS_RATE=$(python -c "import json; print(json.load(open('evaluation_outputs/static/results.json'))['pass_rate'])")
          
          if (( $(echo "$PASS_RATE < 95" | bc -l) )); then
            echo "‚ùå Cannot deploy: Pass rate $PASS_RATE% < 95%"
            exit 1
          fi
          
          echo "‚úÖ Quality gates passed: Proceeding with deployment"
      
      - name: Notify Slack - Deployment Started
        if: env.SLACK_WEBHOOK_URL != ''
        run: |
          curl -X POST "${{ secrets.SLACK_WEBHOOK_URL }}" \
          -H 'Content-Type: application/json' \
          -d '{
            "text": "üöÄ *Deployment to Production Started*",
            "blocks": [
              {
                "type": "header",
                "text": {
                  "type": "plain_text",
                  "text": "üöÄ Deploying to Production"
                }
              },
              {
                "type": "section",
                "fields": [
                  {
                    "type": "mrkdwn",
                    "text": "*Environment:*\nProduction"
                  },
                  {
                    "type": "mrkdwn",
                    "text": "*Branch:*\nmain"
                  },
                  {
                    "type": "mrkdwn",
                    "text": "*Triggered by:*\n${{ github.actor }}"
                  },
                  {
                    "type": "mrkdwn",
                    "text": "*Commit:*\n${{ github.sha }}"
                  }
                ]
              }
            ]
          }'
      
      - name: Deploy to staging
        id: deploy_staging
        run: |
          echo "üöÄ Deploying to staging environment..."
          # Add your staging deployment commands here
          # e.g., kubectl apply -f k8s/staging/
          sleep 2  # Simulate deployment
          echo "‚úÖ Staging deployment complete"
      
      - name: Run smoke tests
        id: smoke_tests
        run: |
          echo "üß™ Running smoke tests..."
          # Add your smoke test commands here
          sleep 2  # Simulate tests
          echo "‚úÖ Smoke tests passed"
      
      - name: Deploy to production
        id: deploy_production
        run: |
          echo "üöÄ Deploying to production environment..."
          # Add your production deployment commands here
          # e.g., kubectl apply -f k8s/production/
          sleep 2  # Simulate deployment
          echo "‚úÖ Production deployment complete"
      
      - name: Notify Slack - Deployment Success
        if: success() && env.SLACK_WEBHOOK_URL != ''
        run: |
          PASS_RATE=$(python -c "import json; print(json.load(open('evaluation_outputs/static/results.json'))['pass_rate'])")
          
          curl -X POST "${{ secrets.SLACK_WEBHOOK_URL }}" \
          -H 'Content-Type: application/json' \
          -d "{
            \"text\": \"üéâ *Deployment to Production Successful*\",
            \"blocks\": [
              {
                \"type\": \"header\",
                \"text\": {
                  \"type\": \"plain_text\",
                  \"text\": \"üéâ Deployment Complete - Production\"
                }
              },
              {
                \"type\": \"section\",
                \"fields\": [
                  {
                    \"type\": \"mrkdwn\",
                    \"text\": \"*Status:*\n‚úÖ Success\"
                  },
                  {
                    \"type\": \"mrkdwn\",
                    \"text\": \"*Quality Gate:*\n${PASS_RATE}% pass rate\"
                  },
                  {
                    \"type\": \"mrkdwn\",
                    \"text\": \"*Environment:*\nProduction\"
                  },
                  {
                    \"type\": \"mrkdwn\",
                    \"text\": \"*Deployed by:*\n${{ github.actor }}\"
                  }
                ]
              },
              {
                \"type\": \"section\",
                \"text\": {
                  \"type\": \"mrkdwn\",
                  \"text\": \"*Deployment Steps:*\n‚úÖ Staging deployed\n‚úÖ Smoke tests passed\n‚úÖ Production deployed\"
                }
              },
              {
                \"type\": \"section\",
                \"text\": {
                  \"type\": \"mrkdwn\",
                  \"text\": \"<${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Deployment Logs>\"
                }
              }
            ],
            \"attachments\": [
              {
                \"color\": \"#2ecc71\"
              }
            ]
          }"
      
      - name: Notify Slack - Deployment Failure
        if: failure() && env.SLACK_WEBHOOK_URL != ''
        run: |
          curl -X POST "${{ secrets.SLACK_WEBHOOK_URL }}" \
          -H 'Content-Type: application/json' \
          -d '{
            "text": "üö® *Deployment to Production Failed*",
            "blocks": [
              {
                "type": "header",
                "text": {
                  "type": "plain_text",
                  "text": "üö® Deployment Failed"
                }
              },
              {
                "type": "section",
                "fields": [
                  {
                    "type": "mrkdwn",
                    "text": "*Status:*\n‚ùå Failed"
                  },
                  {
                    "type": "mrkdwn",
                    "text": "*Environment:*\nProduction"
                  },
                  {
                    "type": "mrkdwn",
                    "text": "*Branch:*\nmain"
                  },
                  {
                    "type": "mrkdwn",
                    "text": "*Actor:*\n${{ github.actor }}"
                  }
                ]
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "‚ö†Ô∏è *Action Required:*\nReview logs and investigate deployment failure."
                }
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "<${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Error Logs>"
                }
              }
            ],
            "attachments": [
              {
                "color": "#e74c3c"
              }
            ]
          }'